{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unidecode\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregunta</th>\n",
       "      <th>respuesta</th>\n",
       "      <th>Tema</th>\n",
       "      <th>Pers/empresa</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hola una pregunta en que perjudica el acta de ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Renuncia/Despido/Desahucio</td>\n",
       "      <td>persona</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PARA CALCULAR EL DESAHUCIO SE DEBE TOMAR EN CU...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Renuncia/Despido/Desahucio</td>\n",
       "      <td>persona</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>supuestamente Correa emitió el decreto 225 dod...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jubilacion Patronal</td>\n",
       "      <td>persona</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Pregunta respuesta  \\\n",
       "0  Hola una pregunta en que perjudica el acta de ...       NaN   \n",
       "1  PARA CALCULAR EL DESAHUCIO SE DEBE TOMAR EN CU...       NaN   \n",
       "2  supuestamente Correa emitió el decreto 225 dod...       NaN   \n",
       "\n",
       "                         Tema Pers/empresa Polarity  \n",
       "0  Renuncia/Despido/Desahucio      persona        0  \n",
       "1  Renuncia/Despido/Desahucio      persona        0  \n",
       "2         Jubilacion Patronal      persona        0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Data\\\\preguntas.csv\", sep=',', encoding = \"ISO-8859-1\")\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = []\n",
    "for p in data.Pregunta:\n",
    "    p2.append(' '.join(p.split()))\n",
    "data['Pregunta2'] = p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stemmer = SnowballStemmer(\"spanish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "jbtopdict = np.load('Data\\\\jbtopdict.npy').item()\n",
    "rentopdict = np.load('Data\\\\rentopdict.npy').item()\n",
    "IESStopdict = np.load('Data\\\\IESStopdict.npy').item()\n",
    "CONTtopdict = np.load('Data\\\\CONTtopdict.npy').item()\n",
    "OStopdict = np.load('Data\\\\OStopdict.npy').item()\n",
    "CONStopdict = np.load('Data\\\\CONStopdict.npy').item()\n",
    "JStopdic = np.load('Data\\\\JStopdict.npy').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_likelihood(t_dict, sentence):\n",
    "    lik = -1\n",
    "    tokens = tokenizer.tokenize(unidecode.unidecode(sentence.lower()))\n",
    "    for w in tokens:\n",
    "        w = stemmer.stem(w)\n",
    "        if w in t_dict:\n",
    "            if lik == -1:\n",
    "                lik = max(t_dict[w], 0.01)\n",
    "            else:\n",
    "                lik *= max(t_dict[w], 0.01)\n",
    "    return lik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_polarity(sentence):\n",
    "    blob = TextBlob(sentence)\n",
    "    blob = blob.translate(to='en').lower() \n",
    "    pol = blob.sentiment[0]\n",
    "    return pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_greet(sentence):\n",
    "    tgreet = ['hol', 'buen', 'tard', 'dias', 'noch']\n",
    "    count = 0\n",
    "    tokens = tokenizer.tokenize(unidecode.unidecode(sentence.lower()))\n",
    "    for w in tokens:\n",
    "        w = stemmer.stem(w)\n",
    "        if w in tgreet:\n",
    "            count += 1            \n",
    "    return count/len(tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_token(sentence):\n",
    "    tokens = tokenizer.tokenize(unidecode.unidecode(sentence.lower()))       \n",
    "    return len(tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['jplik'] = [top_likelihood(jbtopdict, x) for x in data.Pregunta2]\n",
    "data['renlik'] = [top_likelihood(rentopdict, x) for x in data.Pregunta2]\n",
    "data['IESSlik'] = [top_likelihood(IESStopdict, x) for x in data.Pregunta2]\n",
    "data['CONTlik'] = [top_likelihood(CONTtopdict, x) for x in data.Pregunta2]\n",
    "data['OSlik'] = [top_likelihood(OStopdict, x) for x in data.Pregunta2]\n",
    "data['CONSlik'] = [top_likelihood(CONStopdict, x) for x in data.Pregunta2]\n",
    "data['JSlik'] = [top_likelihood(JStopdic, x) for x in data.Pregunta2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['polarity'] = [sentiment_polarity(x) for x in data.Pregunta2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['p_greet'] = [percent_greet(x) for x in data.Pregunta2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['n_token'] = [n_token(x) for x in data.Pregunta2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregunta</th>\n",
       "      <th>respuesta</th>\n",
       "      <th>Tema</th>\n",
       "      <th>Pers/empresa</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Pregunta2</th>\n",
       "      <th>jplik</th>\n",
       "      <th>renlik</th>\n",
       "      <th>IESSlik</th>\n",
       "      <th>CONTlik</th>\n",
       "      <th>OSlik</th>\n",
       "      <th>CONSlik</th>\n",
       "      <th>JSlik</th>\n",
       "      <th>polarity</th>\n",
       "      <th>p_greet</th>\n",
       "      <th>n_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hola una pregunta en que perjudica el acta de ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Renuncia/Despido/Desahucio</td>\n",
       "      <td>persona</td>\n",
       "      <td>0</td>\n",
       "      <td>Hola una pregunta en que perjudica el acta de ...</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>8.571429e-01</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PARA CALCULAR EL DESAHUCIO SE DEBE TOMAR EN CU...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Renuncia/Despido/Desahucio</td>\n",
       "      <td>persona</td>\n",
       "      <td>0</td>\n",
       "      <td>PARA CALCULAR EL DESAHUCIO SE DEBE TOMAR EN CU...</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>8.413462e-02</td>\n",
       "      <td>1.923077e-04</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>supuestamente Correa emitió el decreto 225 dod...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jubilacion Patronal</td>\n",
       "      <td>persona</td>\n",
       "      <td>0</td>\n",
       "      <td>supuestamente Correa emitió el decreto 225 dod...</td>\n",
       "      <td>0.299218</td>\n",
       "      <td>5.917160e-09</td>\n",
       "      <td>1.051940e-08</td>\n",
       "      <td>4.444444e-09</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.111111e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Pregunta respuesta  \\\n",
       "0  Hola una pregunta en que perjudica el acta de ...       NaN   \n",
       "1  PARA CALCULAR EL DESAHUCIO SE DEBE TOMAR EN CU...       NaN   \n",
       "2  supuestamente Correa emitió el decreto 225 dod...       NaN   \n",
       "\n",
       "                         Tema Pers/empresa Polarity  \\\n",
       "0  Renuncia/Despido/Desahucio      persona        0   \n",
       "1  Renuncia/Despido/Desahucio      persona        0   \n",
       "2         Jubilacion Patronal      persona        0   \n",
       "\n",
       "                                           Pregunta2     jplik        renlik  \\\n",
       "0  Hola una pregunta en que perjudica el acta de ...  0.000014  8.571429e-01   \n",
       "1  PARA CALCULAR EL DESAHUCIO SE DEBE TOMAR EN CU...  0.064103  8.413462e-02   \n",
       "2  supuestamente Correa emitió el decreto 225 dod...  0.299218  5.917160e-09   \n",
       "\n",
       "        IESSlik       CONTlik         OSlik       CONSlik         JSlik  \\\n",
       "0  1.000000e-06  1.000000e-06  1.000000e-06  1.000000e-06  1.000000e-06   \n",
       "1  1.923077e-04  1.000000e-06  1.000000e-06  1.000000e-06  1.000000e-06   \n",
       "2  1.051940e-08  4.444444e-09  1.000000e-10  1.000000e-10  1.111111e-09   \n",
       "\n",
       "   polarity   p_greet  n_token  \n",
       "0       0.0  0.076923       13  \n",
       "1       0.0  0.000000       17  \n",
       "2       0.0  0.000000       30  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"Data\\\\preguntas2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net1, self).__init__()\n",
    "        \n",
    "        self.fc11 = nn.Linear(16, 24, bias=True)\n",
    "        self.fc12 = nn.Linear(24, 1, bias=True)\n",
    "        \n",
    "                        \n",
    "    def forward(self, x):\n",
    "        x1 = torch.tanh(self.fc11(x))\n",
    "        x1 = self.fc12(x1)\n",
    "        \n",
    "        x2 = self.fc21(x)\n",
    "        x2 = F.relu(self.fc22(x2))\n",
    "        x2 = self.fc23(x2)              \n",
    "        \n",
    "        x3 = torch.cat((x1, x2), 1)\n",
    "        x3 = self.fc31(x3)\n",
    "        x3 = self.disc_activation(x3)\n",
    "        return x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "    net = net.to(device)\n",
    "    \n",
    "    losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    val_inputs = torch.FloatTensor(X_val)\n",
    "    val_labels = torch.FloatTensor(Y_val)\n",
    "    val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)    \n",
    "    \n",
    "    \n",
    "    for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "    \n",
    "        running_loss = 0\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        counter = 0\n",
    "            \n",
    "        for batch_x, batch_y in batch_generator(X, Y, n_batches):  \n",
    "            \n",
    "            counter += 1 \n",
    "                       \n",
    "            net.train()\n",
    "            # get the inputs\n",
    "            inputs = torch.FloatTensor(batch_x)\n",
    "            labels = torch.FloatTensor(batch_y)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)             \n",
    "                \n",
    "    \n",
    "            # forward + backward + optimize\n",
    "            outputs = net.forward(inputs)\n",
    "            loss = error(outputs, labels)\n",
    "                        \n",
    "            loss.backward()            \n",
    "            \n",
    "            running_loss += loss.item()        \n",
    "            \n",
    "            if counter % batch_to_avg == 0:\n",
    "                \n",
    "                torch.nn.utils.clip_grad_norm_(net.parameters(), clipping) \n",
    "                \n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()         \n",
    "                \n",
    "                \n",
    "        running_loss = running_loss/n_batches       \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            val_outputs = net.forward(val_inputs)\n",
    "            \n",
    "            val_outputs2, val_labels2 = val_outputs.cpu(), val_labels.cpu()\n",
    "            val_outputs2, val_labels2 = val_outputs2.numpy(), val_labels2.numpy()\n",
    "            \n",
    "            val_loss = val_error(val_outputs2, val_labels2)\n",
    "           \n",
    "        \n",
    "        losses.append(running_loss)\n",
    "        val_losses.append(val_loss)        \n",
    "        \n",
    "        \n",
    "        if verbose == 1:\n",
    "            print('Epoch {0}: Training Loss: {1}, Validation Loss: {2}'\\\n",
    "                  .format(epoch+1, running_loss, val_loss))\n",
    "        \n",
    "        \n",
    "        \n",
    "        if (epoch % ep_to_check == 0) and (epoch >= ep_to_check):\n",
    "            \n",
    "            mean_val_loss = np.mean(val_losses[-ep_to_check:])\n",
    "        \n",
    "            \n",
    "              \n",
    "            if mean_val_loss < min_val_loss:\n",
    "        \n",
    "           \n",
    "                torch.save(net.state_dict(), PATH)\n",
    "                if verbose == 1:\n",
    "                    print('New Checkpoint Saved into PATH')\n",
    "                min_val_loss = mean_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://discuss.pytorch.org/t/passing-the-weights-to-crossentropyloss-correctly/14731"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
